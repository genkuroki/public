# ソース

* https://sites.stat.columbia.edu/gelman/research/unpublished/external_incentives.pdf
* Normative scientific conflict is unavoidable and should be welcomed
* Andrew Gelman (Department of Statistics and Department of Political Science, Columbia University, New York,
ag389@columbia.edu)
* 26 Jul 2025
* [NotebookLMによる音声概要](https://genkuroki.github.io/audio/75%20Normative%20scientific%20conflict%20is%20unavoidable%20and%20should%20be%20welcomed.m4a)

以下はこれのChatGPTによる機械翻訳である。

---

# 規範的な科学的対立は避けられないものであり、歓迎すべきである

* Andrew Gelman
* 2025年7月26日

要旨: 科学改革運動は、科学的問い、研究方法、そして科学的知見の政治的含意に関わる、いくつかの異なる種類の規範的対立を含んでいる。科学的対立のいくつかの源泉を簡単に振り返った後、劣悪な学問を生み出す内的・外的な誘因を検討し、最後に公表された科学に関する規範的対立をより全面的に受け入れることを推奨する。我々は、このような対立が消えることを期待することさえせず、むしろ科学における規範的対立をより広く受け入れることを推奨する。

------

科学改革運動には、いくつかの異なる種類の規範的対立が含まれている。最も直接的には、現在の出版や昇進の制度を深刻に欠陥があるとみなす「改革者」と、改革のコストはその利益より大きいとみなす「体制側」との間に対立がある。逆の方向から言えば、これは「科学に専念し、結果はなるようになる」と考える「実行者」と、「研究の邪魔をする」と見なされがちな「批判者」との対立として捉えることもできる。誰もが、発表され広められた研究の一部には誤りがあることを認めており、争点は特定の論文、サブフィールド、あるいはデータ共有、事前登録、出版後レビューといった改革提案のレベルで生じる。

もう一つの規範的対立の形態は政治に関わるもので、弱い証拠が社会的に強い含意をもつ見解の推進に使われる場合である。これは政治的にさまざまな方向から生じうる。左派における根拠の乏しい主張の例としては、幼児期介入の大きな効果があるとされるものがある（Gelman, 2013; Farran and Lipsey, 2017 を参照）。右派における例としては、選挙不正に関する主張や性比に関する性本質主義的な憶測がある（Eggers, Garro, and Grimmer, 2021; Gelman and Weakliem, 2009 を参照）。これは、潜在的な人種差別、就学前教育プログラム、選挙不正、進化心理学といったテーマを研究すべきでない、ということを意味してはいない。むしろ、p値などによって提供される証拠に関する科学的な不可避の争いが、政治的な不一致と混同されやすい、という点を指摘しているのである。

また、政治的アドボカシーを行う人々が研究をしてはならない、という議論もすべきではない。潜在的な政策を擁護する人々がその効果を研究したいと思うのは理にかなっている。科学的観点から重要なのは、データと方法を公開し、その研究が独立に評価できるようにすることであり、またアドボケイトが自分たちの誤りの可能性に対して開かれた態度をとることである。知識論的観点からは、証拠と真理を区別する必要がある。研究者やアドボケイトは、あるパターン（たとえば、特定の就学前プログラムが新しい母集団に適用された場合に大きな効果をもたらすとか、より魅力的な親の方が女児を産みやすいなど）を信じる自由を持つべきだが、同時に、利用可能なデータはこれらの信念を経験的に検証するには不十分であることを認識すべきである。強い証拠があるという不適切な主張を手放すことは、その信念自体を手放すことを必ずしも要求しない──ただし、それによって代替的な見解を受け入れる姿勢は強まるべきである。

科学的主張は、明確な政治的傾向を持たなくても論争を呼ぶことがある。たとえば、大学フットボールの試合やサメの襲撃といった無関係な出来事によって選挙結果が左右されるという主張（Fowler and Montagnes, 2015; Fowler and Hall, 2018 を参照）は、選挙は国民の意見を測る有意義な手段ではない、という見解を支えるものと解釈できるが、この見解が「左派」か「右派」かは現在の権力者によって異なる。「ナッジ」や「自由主義的パターナリズム」の効果に関する誇大な主張（Thaler and Sunstein, 2008）は、活動的な政府に道具を与えるという意味で漠然と左派的であり、企業が従業員を支配しやすくするという意味で漠然と右派的でもある。こうした主張の反証（たとえば Szászi et al., 2022）は、したがって政治的に曖昧な含意を持つ。パレオダイエットや冷水シャワーの効用に関する根拠のない主張（Gelman, 2023 を参照）は、直接的な政治的含意を持たないが、漠然と右派的な「マノスフィア」的な雰囲気を帯びている。党派的分極化の時代においては、ほとんどあらゆる科学的主張が政治的に分極化しうる──最近まで左派や右派と結び付けられていなかった小児ワクチンの危険性に関する既に否定された主張が再利用されているのはその一例である。

過去20年間に、社会科学や生物科学における劣悪な研究へと注目を集めた再現性危機が生じた。これには、著名な再現失敗の事例、絶望的にノイズの多い実験、科学的にもっともらしくない主張、そして露骨な不正が含まれる。この時期にこれらの問題がなぜこれほど注目されるようになったのかは完全には明らかでない（Gelman and Vazire, 2021）。他の制度的失敗と同様に、何が悪かったのか、どう修正できるのかを追跡することへの関心がある。しかしその課題は特に困難である。なぜなら、現在の論文の著者を含め科学改革に取り組んでいる多くの人々が、致命的に欠陥のある研究をこれまで報酬し、今も報酬し続けている同じ学術構造の一部だからである。我々は、フィルム・ノワールの登場人物に似た立場にある。すなわち、組織内部のグループによって犯された犯罪を捜査する（あるいは場合によっては隠蔽する──その使命は意図的に曖昧にされうる）任務を与えられた人物に似ているのである（Farrow, 1948）。

なぜこれほど多くの粗悪な科学研究があるのだろうか？最も単純な答えは、科学は難しく、成熟した分野における進歩は漸進的なものになりがちだからである。同時に、絶え間ないブレークスルーが求められている。Science や Nature といったトップジャーナルや、NPR や TED のようなニュース・広報媒体は、常に最新の成功事例を報じる準備ができている。たとえば、2015年に雑誌 Pacific Standard は「Findings」という特集を掲載していた。これは「Pacific Standard のスタッフライターであるトム・ジェイコブズによる毎日のコラムで、心理学研究誌を精査し、人間行動に関する新しい洞察──我々の政治的信念の起源から創造性の育成まで──を発見するもの」と説明されていた。年間365もの人間行動に関する新しい洞察を発見する──これは大きなプレッシャーだ！私たちはこのコラムが、イギリス心理学会でも取り上げられた論文を宣伝していたときに目にした。その論文は「なじみがあり好まれる音楽に触れると、第三者を傷つけることを含意する要請への服従が増える」と主張していた（Gelman, 2015; Jacobs, 2015; Jarrett, 2015）。しかし注意深く見ると、その論文は何ら強い証拠を提供していなかった。シモンズ、ネルソン、シモンソーン（2011）が一般的に説明したように、研究者の自由度が制御されていないと、純粋なノイズから見かけ上強い統計的主張を引き出すことができてしまう。ここでのポイントは、この特定の研究に注目することではなく、漸進的で試行錯誤的な科学の現実と、定期的なブレークスルーを求める需要との衝突を示すことである。

何百万人もの科学者が活動している世界では、そのうち十分な数の科学者が偶然にも十分に刺激的で再現可能な発見に出会うだろうと期待するかもしれない。しかし必ずしもそうはならない。社会科学や生物科学における大衆受けする研究の多くは、ノイズが大きすぎて成功の可能性が全くない。私たちは以前に議論した研究でこれを例示する（Gelman and Weakliem, 2009; Denny, 2008 も参照）。2000年代初頭、Journal of Theoretical Biology は「大きく背の高い親は息子が多い」「エンジニアは息子が多く、看護師は娘が多い」「暴力的な男性は息子が多い」といったタイトルの一連の論文を掲載した（例：Kanazawa, 2007）。残念ながら──あるいは幸いなことに──これらの研究はいずれも性比について一般化可能な知識をもたらす可能性を持っていなかった。問題は数学的である。女児出生の確率は約49%である。これらの研究は、サンプルサイズが3,000から25,000の範囲にある調査データを基に、異なる集団の性比を比較している。仮にこの範囲の上限にある研究があり、2つのグループ（たとえば、背の高い親の子どもと低い親の子ども）における女児の割合を比較するとしよう。この差の標準誤差は √(0.52/12500 + 0.52/12500) = 0.006 であり、すなわち 0.6 パーセントポイントである。ある目的にはこの推定は非常に精密かもしれないが、性比の研究にはあまり役立たない。なぜなら、出生順位、人種、母親の年齢といった要因による性比の観察された集団差は通常 0.5 パーセントポイント未満だからである。推定の標準誤差が現実的な効果量より大きい研究は、絶望的なのである。

まさにこの問題──変動の制御が不十分で最初から失敗が避けられない実験──は、標準的な統計的枠組みの下では覆い隠されてしまうことがある。ある研究の統計的検出力が10%であるということは、特定の仮定の下で、その研究が統計的に有意な結果を示す確率が10%であることを意味する。医療研究では通常、少なくとも80%の検出力が求められるが、それにはそれなりの理由がある。成功の見込みが十分でないのに患者を危険にさらすことは避けたいからである。しかし、参加者にリスクがなく費用も最小限の社会調査や実験、あるいは既存データの再解析の場合、「なぜ検出力10%の研究をしてはいけないのか」と思うかもしれない。これは「10回に1回の当たり」を意味し、もし100人の研究者がそれぞれの研究室でそのような実験を行えば、10人が発見をすることになるではないか？──実際にはそうではない。そのような状況で統計的に有意な発見が得られても、符号や大きさにおいて再現される可能性は低いからである（Button et al., 2013; Gelman and Carlin, 2014）。pハッキングのような疑わしい研究手法がなくても、ノイズの多い研究環境では統計的に有意でありながら再現不可能な結果が定期的に生産されてしまう。

長年にわたり、我々は粗悪な学問を生み出す多くの内的誘因を認識するようになった。キャリアの向上には、博士課程の指導教員から「公表済みの研究を批判するな」といった直接の助言が含まれる場合すらある（Luebbert and Pachter, 2024）。イデオロギーへの同調は、意図的な政治的アドボカシー行為から生じることもあれば、あるサブフィールドに内面化され、採用やSNS、閉ざされた研究コミュニティを通じて強制されることもある（Gelman, 2024）。査読プロセスは、2010年から2015年頃に Psychological Science 誌に掲載された社会心理学の研究が悪名高く示したように、サブフィールド内の既存の方法論的・理論的枠組みを現実と混同させる。著者や雑誌の防衛的、あるいは不在の対応によって、出版後の批判は背景に追いやられる。大学の懲戒プロセスは、学問的不正行為が明白な場合ですら弱く、学会組織にも同様の失敗がある（たとえば、アメリカ統計学会は政治的に物議を醸した統計学者ロナルド・フィッシャーに関連する講義の名称を改める手間をかけながら、複数の論文を剽窃した統計学者に授与した賞を取り消すことは拒否した）。データ共有が行われない慣行は、科学研究を精査したり再現したりすることを困難にする。出版プロセスは、大胆な主張や奇抜なアイデアの宣伝を優遇する。その中には「聖書の暗号」や超能力といった悪名高い題材も含まれる（Bar Hillel et al., 1999; Ritchie et al., 2012）。論文内部や出版選択における恣意的選択の容認は、好ましい理論を支持しているように見える結果だけを示す論文を生み出し、証拠の整合性に関する誤った印象を作り出す。著者、査読者、雑誌はしばしば明白に不正確な研究要約を公表することをいとわない。たとえば、わずか3日間しか続かなかった心理学研究を「長期的」と説明したり、参加者が「即座により強力になる」と主張しながらもパワーの測定を一切含まない論文などがある（Hasan et al., 2013; Carney et al., 2010）。また、発表済みの研究は正しいと仮定されがちな既得権益の優位性もあり、その一因として査読プロセスの過大評価が挙げられる。

粗悪な学問を生み出す誘因は学界外にも存在する。上述のとおり、ニュースやSNSは新しい発見への飽くなき欲望を持っており、最も劇的な発言をする科学者こそが注目を集める。外部資金の獲得欲求は、同調と確実性の主張を動機づける。政治的干渉は、発表される研究内容や研究努力に値すると見なされる分野、さらには既に否定された研究の積極的な宣伝にまで影響を及ぼしうる（例：BBC Verify Team, 2024）。

これほど多くの「悪しき学問」を助長する誘因がある中で、進歩に希望はあるのだろうか？
科学改革が議論を呼ぶのは当然である。というのも、ある研究分野に属する研究者にとっては、監視の強化によって不利益を被ることになるからだ。科学改革者たちは、ほとんどの場合、自分の時間を割いて調査活動を行っており（Retraction Watch, 2025 を例外とする程度である）、さらに論文が文献の中で反駁されても、元の論文はその批判的アップデートよりも高い頻度で引用され続けることがある。オープンサイエンスへの資金援助は一部存在し、事前登録による追試などオープンサイエンス的実践への支持も高まりつつある。したがって、われわれが期待できる最良の状態は、おそらく「研究の主張が出版後に批判的レビューに晒される」ことが常態化した新しい均衡であろう。このプロセスでは、信頼の重心が雑誌編集者や査読者から、尊敬を集める第三者へと移る。そしてその第三者自身もまた批判の対象となりうる、という具合である。

それでも、状況が絶望的だとは考えていない。科学的コンセンサスは多くの領域で確立されており、誤ったコンセンサス（たとえば、つい最近まで社会心理学で広く信じられていた「プライミング効果は大きく一貫している」という考え）は、当該分野の外部から懐疑の目にさらされるに至った。根拠のない主張が消え去ることはないだろう。たとえば前述の「ワクチンと自閉症の関連」に関する信念、あるいは何千年も生き残っている占星術などである。しかし、そうした領域は少なくとも「根拠薄弱」であることが広く認識されている。

規範的な科学的対立に関して最も重要な一歩は、それが「存在するのだ」と認めることだろう。不幸にして、科学出版の多くの仕組みは、最終的な成果物において公開の対立を矮小化する方向に構造化されている。査読過程では多くの争いがあり、ときに醜い対立にさえなる（例：Gelman, 2022）が、一度論文が出版されると、それを公に批判するのは行儀が悪いとされ、「身内の中で争いを済ませるべき」という態度が支配的になる。このパターン――査読中の激しい対立と、出版後に仮託される確実性――は、長らく論争の的となってきた有意性検定の枠組みを鏡写しにしたものとも言える（Krantz, 1999 を参照）。すなわち、ゼロ仮説の有意な再現が、提示された理論を強く支持する証拠とみなされるのである。論文が出版の壁を突破したという事実自体が、その論文を科学の正典に押し上げるかのように扱われる。だが、統計的有意なパターンは偶然や p-hacking によって日常的に生じるため、これはサブプライム危機に類似している。すなわち、多くの不安定な投資商品が「トランシェ化」され、安定しているかのような誤った印象を作り出した（Gelman and Loken, 2014）。

正当な科学的・政治的対立が存在することを認めることは、そうした不一致をより公開の形で解決するための第一歩となる。解決は、データの再分析、追試、そして理想的には研究者自身や当該分野の関係者による再評価からもたらされるだろう。「悪しき学問」を助長するインセンティブを認識することの目的は、それを免罪することでも、即座の改革を提案することでもない。たとえば、自らの研究を明らかに誤った要約で発表する研究者をどうやって抑止するかについて、われわれには解決策がない。ただし重要なのは、「出版後の対立は存在しない」という否認から脱却することだ。われわれは、科学における規範的対立の広い受容を推奨する。それは決して、対立が消えることを期待するためではない。

もしわれわれが「公開された規範的対立」を望ましいと受け入れるならば、それを促進するためにどのような措置がとれるだろうか？すでにいくつかの進展がある。多くの雑誌はデータやコードの共有を必須化している。さらに、雑誌は査読報告を公開し、出版後批判を論文とともに直接参照できるようにし、頻繁に引用される論文に対して公式の再評価を予定し（Gelman and King, 2025）、さらに真剣な批判を――元論文よりも高い基準を課さずに――掲載し、希望するなら著者からの応答も添える、といったことが可能である。

不成功に終わった追試の結果も公表することを標準とすべきだが、これは難しい。2011年には、超感覚的知覚（ESP）の存在を示す主張が心理学の一流誌に掲載され、ニューヨーク・タイムズの一面でも取り上げられた。ところが、追試が失敗した報告は、ほぼ何でも掲載するアーカイブ的な雑誌 PLoS One に発表された。しかしこれはある意味で理にかなっている。ESP の真の発見であれば科学的な大突破口となっただろうが、追試が無効であるという結果は全く驚くべきものではないからである。我々は、主要な学術誌が「重力が実在する」「永久機関は実際には作動しない」「第二次世界大戦は本当にあった」といった確認で紙面を埋め尽くすことを望まないだろう。虚偽の主張のほうが真実よりも刺激的である、という不快な非対称性が存在する。しかし、雑誌がすべての追試を掲載しなければならないわけではない。その雑誌自身が掲載した論文については、真剣な追試の結果を（オンラインで）すべて公表する義務を負うべきだ。この方が公平である。栄光や注目を得る可能性と引き換えに、その後処理を担う責任も負うことになるからである。

したがって我々は、例外的な場合にのみ批判や追試を掲載するのではなく、明らかな問題がない限り、雑誌はそれらをデフォルトで掲載すべきだと提案する。（批判者や追試者がこの方法で安易に業績を稼ぐことを懸念するのであれば、その投稿にラベルを付ければよい。例えば「Journal of X: Criticisms and Replications」のように。）さらに、批判への応答を著者に自動的に依頼し、これらすべてをオンラインで公開し、元の論文からアクセス可能にすることも推奨する。

しかし、この一連の取り組みの行き着く先は何なのだろうか？　誰も「最後の言葉」を得られず、人間のよく知られた頑固さのパターンや、誤りを認めることへのインセンティブ不足を考えれば、満足のいく「決着」に至ると期待するのは現実的ではない。この争いには勝者はなく、無期限に続く可能性がある。しかし、規範的な科学的対立そのものを善とみなすならば、それで構わない。個別の事例で「決着」を望む気持ちはあったとしても、対立を促進するというより大きな目標のために不満を飲み込むべきだ。

この立場が単なる当たり前で無害な主張に見えるかもしれないが——カール・ポパーらが強調してきたように、研究の将来の方向性は予期せぬものであるのが本質だ——現在の学術誌の出版システムが、ここで提案しているものとはほとんど正反対であることを思い出してほしい。現状では、一度論文が出版されると、合意を強制する方向に圧力がかかるのだ。

例を挙げよう。2024年、雑誌 Daedalus は「Understanding Implicit Bias: Insights & Innovations（暗黙のバイアスを理解する：洞察と革新）」という特集号を刊行した。掲載記事のひとつは「The Science of Implicit Race Bias: Evidence from the Implicit Association Test（暗黙の人種バイアスの科学：IATからの証拠）」、もうひとつは「The Implicit Association Test（暗黙の連合テスト）」であり、その他にも暗黙のバイアスの影響に関する論文があった。しかし、懐疑的な見解は一切示されていなかった。数本の論文では、わずかに異論が触れられ引用されていたが、それもごく短く、しかも IAT を正当なものとして扱う文脈の中でである。このトピックの論争の大きさを考えると（例えば Goldhill, 2017 を参照）、この号に掲載された全18本の論文が同じ立場を取っていたことには驚かされた。「暗黙のバイアスは確かに存在するが、IAT を使って測定すべきではない」といった論文が数本あってもよかったのではないだろうか。あるいは序論の中で「IAT は論争の的であり、深刻な批判を受けてきた（参考文献）；それにもかかわらず、いくつかの論文を掲載する理由は…」と述べるスペースを設けるべきではなかったのか。

簡単な答えは、「いや、それは雑誌の判断であり、彼らは好きにできる」ということであり、この出版物が論争を解消するわけではない。規範的な科学的論争は残る──この場合、方法論的、実質的、政治的な次元を含む──したがって本質的に問われるのは、この論争が Daedalus 内でも起きているか、あるいは雑誌がより大きな争点の中で統一的な立場を示しているか、ということである。私は前者を望むが、その見解を支持する証拠は提示できない。

解決されない規範的科学的論争が常に存在することの不幸な副作用は、さまざまな誤った、場合によっては危険な考えが消えないことである。現在の例としては、アメリカ保健福祉長官が、信用されていない、偽造された、あるいは完全に作り上げられた研究に基づいて反ワクチン思想を促進していることが挙げられる（Jacobs, 2025）。すぐに影響のある問題でなくても、幽霊や宇宙人の訪問、社会的プライミングの極端なバリエーションに関する信念が依然として残っている。問題は、人々が信じられない考えを抱いていること自体ではない──結局のところ、一部の非現実的な考えが正しいこともありうるし、大規模な科学コミュニティの利点のひとつは、少数意見やリスクの高いアイディアを追求する余地があることである。問題は、人々がそのような信念を支持する証拠を誤って伝える場合に生じる。科学は自己修正的である可能性があるが、経済的・政治的に開かれた社会においてさえ、人々が証拠を誤って伝える政治的・個人的動機は常に存在する。

歴史家 A. J. P. Taylor が「強い政治的見解を持っているか」と問われた際、「いいえ。極端な意見を弱く持つ」と答えた。少なくとも個人として、我々は科学にもこの姿勢で臨むべきかもしれない。ここでの難しさは、解決策がない点として、科学者は三つの役割を同時に、あるいは交互に演じることがあることである。第一の役割は推測およびある種の科学的（必ずしも政治的ではない）アドボカシーである：自分のアイデアを信じ、他者もその見解に同意することを望み、そのための証拠や論拠を探す。第二の役割は自己批判者であり、Feynman（1974）の格言「第一の原則は、自分を騙してはいけない——そして自分が最も騙されやすい人間である」を遵守する。この二つの役割を演じることで、科学的対立を自らの内に具現化する──これは現役科学者において必ずしも一般的ではないかもしれない。しかし、第三の役割として、証拠の冷静な審査者としての立場もある。我々は暫定的な結論に至る必要があり、その際には一定の成熟が求められる。規範的科学的対立を受け入れ、さらには歓迎することは、手元のデータに基づいて合理的な結論を導く意欲と表裏一体である。

## 参考文献

* Maya Bar-Hillel, Dror Bar-Natan, Gil Kalai, and Brendan McKay (1999). Solving the Bible Code puzzle. Statistical Science 14, 150-173.
* BBC Verify Team (2024). Fact-checking RFK Jr.’s views on health policy. BBC, 15 Nov. https://www.bbc.com/news/articles/c0mzk2y41zvo/
* Katherine S. Button, John P. A. Ioannidis, Claire Mokrysz, Brian A. Nosek, Jonathan, Emma S. J. Robinson, and Marcus R. Munafò (2013). Power failure: Why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience 14, 365-376.
* Dana R. Carney, Amy J. C. Cuddy, and Andy J. Yap (2010). Power posing: Brief nonverbal displays affect neuroendocrine levels and risk tolerance. Psychological Science 21, 1363-1368.
* Kevin Denny (2008). Big and tall parents do not have more sons. Journal of Theoretical Biology 250, 752-753.
* Andrew C. Eggers, Haritz Garro, and Justin Grimmer (2021). No evidence for systematic voter fraud: A guide to statistical claims about the 2020 election. Proceedings of the National Academy of Sciences 118, e2103619118.
* Dale C. Farran and Mark W. Lipsey (2017). Misrepresented evidence doesn’t serve pre-K programs well. Brookings Institution, 24 Feb. https://www.brookings.edu/articles/misrepresented-evidence-doesnt-serve-pre-k-programs-well/
* John Farrow (1948). The Big Clock. Paramount.
* Richard P. Feynman (1974). Cargo cult science. Commencement address, California Institute of Technology. https://calteches.library.caltech.edu/51/2/CargoCult.htm
* Anthony Fowler and Andrew B. Hall (2018). Do shark attacks influence presidential elections? Reassessing a prominent finding on voter competence. Journal of Politics 80, 1423-1437.
* Anthony Fowler and B. Pablo Montagnes (2015). College football, elections, and false-positive results in observational research. Proceedings of the National Academy of Sciences 112, 13800-13804.
* Andrew Gelman (2013). Childhood intervention and earnings. Symposium Magazine, 3 Nov. https://web.archive.org/web/20131118074128/http://www.symposium-magazine.com/childhood-intervention-and-earnings/
* Andrew Gelman (2015). The aching desire for regular scientific breakthroughs. Statistical Modeling, Causal Inference, and Social Science, 16 Sep. https://statmodeling.stat.columbia.edu/2015/09/16/harsh/
* Andrew Gelman (2022). How do things work at top econ journals, exactly? Statistical Modeling, Causal Inference, and Social Science, 25 Jan. https://statmodeling.stat.columbia.edu/2022/01/25/how-do-things-work-at-top-econ-journals-exactly-this-is-one-weird-ass-story/
* Andrew Gelman (2023). Before reading this post, take a cold shower: A Stanford professor says it’s “great training for the mind”! Statistical Modeling, Causal Inference, and Social Science, 8 Jul. https://statmodeling.stat.columbia.edu/2023/07/08/before-reading-this-post-take-a-cold-shower-a-stanford-professor-its-great-training-for-the-mind/
* Andrew Gelman (2024). Implicitly denying the controversy associated with the Implicit Association Test. Statistical Modeling, Causal Inference, and Social Science, 20 Aug. https://statmodeling.stat.columbia.edu/2024/08/20/when-is-it-appropriate-to-give-a-one-sided-perspective-implicit-association-test-example/
* Andrew Gelman and John B. Carlin (2014). Beyond power calculations: Assessing Type S (sign) and Type M (magnitude) errors. Perspectives on Psychological Science 9, 641-651.
* Andrew Gelman and Andrew King (2025). Social science is broken. Here’s how to fix it. Chronicle of Higher Education, 25 Feb.
* Andrew Gelman and Eric Loken (2014). The AAA tranche of subprime science. Chance 27 (1), 51-56.
* Andrew Gelman and Simine Vazire (2021). Why did it take so many decades for the behavioral sciences to develop a sense of crisis around methodology and replication? Journal of Methods and Measurement in the Social Sciences 12, 37-41.
* Andrew Gelman and David Weakliem (2009). Of beauty, sex, and power: Statistical challenges in estimating small effects. American Scientist 97, 310-316.
* Olivia Goldhill (2017). The world is relying on a flawed psychological test to fight racism. Quartz, 3 Dec. https://qz.com/1144504/the-world-is-relying-on-a-flawed-psychological-test-to-fight-racism
* Youssef Hasan, Laurent Bègue, Michael Scharkow, and Brad Bushman (2013). The more you play, the more aggressive you become: A long-term experimental study of cumulative violent video game effects on hostile expectations and aggressive behavior. Journal of Experimental Social Psychology 49, 224-227.
* Phie Jacobs (2025). Trump officials downplay fake citations in high-profile report on children’s health. Science, 30 May. https://www.science.org/content/article/trump-officials-downplay-fake-citations-high-profile-report-children-s-health
* Tom Jacobs (2015). The dark side of music. Pacific Standard, 31 Aug. https://psmag.com/social-justice/the-dark-side-of-the-power-of-music/
* Christian Jarrett (2015). Background positive music increases people's willingness to do others harm. British Psychological Society Research Digest, 15 Sep. https://www.bps.org.uk/research-digest/background-positive-music-increases-peoples-willingness-do-others-harm
* Satoshi Kanazawa (2007). Beautiful parents have more daughters: A further implication of the generalized Trivers-Willard hypothesis. Journal of Theoretical Biology 244, 133-140.
* David H. Krantz (1999). The null hypothesis testing controversy in psychology. Journal of the American Statistical Association 44, 1372-1381.
* Laura Luebbert and Lior Pachter (2014). The journal of scientific integrity. Bits of DNA, 2 Jul. https://liorpachter.wordpress.com/2024/07/02/the-journal-of-scientific-integrity/
* Retraction Watch (2025). Meet the first two Retraction Watch Sleuths in Residence. Retraction Watch, 27 May. https://retractionwatch.com/2025/05/27/meet-the-first-two-retraction-watch-sleuths-in-residence/
* Stuart J. Ritchie, Richard Wiseman, and Christopher C. French (2012). Failing the future: Three unsuccessful attempts to replicate Bem’s “retroactive facilitation of recall” effect. PLoS One 7, e33423.
* Joseph P. Simmons, Leif D. Nelson, and Uri Simonsohn (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological Science 22, 1359-1366.
* Barnabás Szászi, Anthony C. Higney, Aaron B. Charlton, Andrew Gelman, Ignazio Ziano, Balacs Aczel, Daniel G. Goldstein, David S. Yeager, and Elizabeth Tipton (2022). No reason to expect large and consistent effects of nudge interventions. Proceedings of the National Academy of Sciences 119, e2200732119.
* A. J. P. Taylor (1977). Accident prone, or what happened next. Journal of Modern History 49, 1-18.
* Richard H. Thaler and Cass R. Sunstein (2008). Nudge: Improving Decisions About Health, Wealth, and Happiness. Yale University Press.

