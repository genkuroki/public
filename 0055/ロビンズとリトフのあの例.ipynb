{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b84d01-fe38-46fa-8bc0-dc29b96d85d1",
   "metadata": {},
   "source": [
    "# ロビンズとリトフのあの例について；あるいは港にいる眠れる犬は安全だが、それが眠れる犬のいるべき場所ではない\n",
    "\n",
    "ソース: https://dansblog.netlify.app/posts/2022-11-12-robins-ritov/robins-ritov\n",
    "\n",
    "On that example of Robins and Ritov; or A sleeping dog in harbor is safe, but that’s not what sleeping dogs are for\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "## 時にはそれは不毛なイチジクの木のたとえ話のようなものだ。時にはただ、低木に腹を立てているだけだ。\n",
    "\n",
    "統計学の分野において、パラドックスや反例は単なる理論上の奇妙な事例ではありません。これらはコミュニティの共有財産として、いわば「教訓話」や「怪談」のような役割を果たします。それらは、理論の森へと続く道沿いに立つ不気味なガソリンスタンドの店員のように、冒険者に進路変更を強いるのではなく、その先に潜む潜在的な危険を示す道標として機能するのです。[^1]\n",
    "\n",
    "時には、それは実のならないイチジクの木のたとえ話のようであり、また時には、単に低木に腹を立てているだけのことかもしれません。\n",
    "\n",
    "原則として、私たちはこれらのパラドックスや反例を解決しようとする試みにも、疑いの目を向けるべきです。それらは、そのためにあるのではありません。それらはコミュニティの資源であり、私たちの集合的文化の対象であり、妨げられた願望の記念碑なのです。\n",
    "\n",
    "しかし、時には、コンテンツへの尽きることのない渇望に駆られて、反例に飛び込み、それを解決する価値があることもあります。このドン・キホーテ的な探求は、どこかの穴を塞ぐためではなく、むしろその穴を、私たちの欲求、必要性、そして祈りを快適に包み込めるまで広げるためのものです。\n",
    "\n",
    "その目的のために、キャンプファイヤーの周りに集まり、「ベイジアンと補助的なコイン」の物語に耳を傾けましょう。\n",
    "\n",
    "この例[^2]はロビンズとリトフによって導入され、ラリー・ワッサーマンによって大いに広められました（そして頻繁に再定式化されました）[^3]。それは次のように述べています[^4]。\n",
    "\n",
    ">コミットした主観的ベイジアン（ローズがあのドアにしがみつくよりも固く尤度原理に固執する者）は、単純だが現実的なランダム化の形式の下で、時には非常に間違った答えを出すことがある。それほどコミットしていないベイジアンだけが、その危険を回避することができる。\n",
    "\n",
    "これが、これから私たちが行うことです。まず、この反例を引き起こさない問題のバージョンを紹介します。次に、エラーにつながるランダム化スキームを導入し、具体的に何がどう間違っているのかを議論します。純粋性に関するいかなる主張にも特に懐疑的な人間として[^5]、次の仕事は、このコミットした[^6]主観的ベイジアンという考えを解体することです。おそらく驚くには当たらないでしょうが、私は、ロビンズとリトフ（そしてワッサーマン）の結論の中で、いささか疑問の余地があるのはこの部分だけだと主張します。実際、真のコミットした主観的ベイジアン[^7]は、この問題を解決できるのです。それは単に、正しいレンズを通してそれを見ることの問題なのです。\n",
    "\n",
    "## 反例は常に最も興味深くない前提から生じる\n",
    "\n",
    "この例は多くの形式で存在し、それぞれが問題に重要な側面を加えていますが、単純化のために、問題が起こらない簡単な状況から始めます。\n",
    "\n",
    "大きく、しかし固定された有限の数 $J$ があり、 $J$ 個の未知のパラメータ $\\mu_j$ （ $j=1,\\ldots, J$ ）があると仮定します。この大きな数 $J$ は、母集団における層の数と考えることができ、 $\\mu_j$ は対応する層の平均です。ここで、次のような実験を構築します。\n",
    "\n",
    "$$ y_i \\mid \\mu,x = j \\sim N(\\mu_j, 1). $$\n",
    "\n",
    "この生成モデルを完成させるために、共変量は既知の分布 $x_i \\sim \\text{Unif}\\{1,\\ldots, p\\}$ に従うと仮定します。\n",
    "\n",
    "数理統計学における古典的な問題は、ベクトル $\\mu$ の $\\sqrt{n}$ -consistent[^8]な推定量 $\\hat\\mu_n$ を構築することです。しかし、この問題設定では、これは非常に困難です。課題は、 $J$ が非常に大きな数である場合、すべてのパラメータを適切に解決するためには、膨大な[^9]数の観測（ $n \\gg J$ ）が必要になるということです。\n",
    "\n",
    "## しかし、救いがあります！ 母集団[^10]平均\n",
    "\n",
    "$$ \\mu = \\mathbb{E}(y) = \\sum_{j=1}^J \\mu_j \\Pr(x = j)= \\frac{1}{J}\\sum_{j=1}^J \\mu_j $$\n",
    "\n",
    "は、かなり簡単に推定できます。実際、標本平均（すなわち最も明白な推定量） $\\bar{y} = n^{-1} \\sum_{i=1}^n y_i$ は、 $\\sqrt{n}$ -consistentになります。\n",
    "\n",
    "同様に、事前分布 $\\mu_j \\mid m \\sim N(m, 1)$ と $m \\sim N(0,\\tau^2)$ に基づいて母集団平均のベイジアン推定を構築した場合、母集団平均の事後推定値は、十分に大きな[^11] $n$ に対して、\n",
    "\n",
    "$$ \\hat \\mu_{\\text{Bayes},n}= \\mathbb{E}(\\mu \\mid y) \\approx \\frac{1}{n + 2/\\tau} \\sum_{i=1}^n y_i. $$\n",
    "\n",
    "となります。これは、この問題のベイジアンによる解決法が、古典的な解決法とほぼ同じであることを意味します。これは良いことです。非常に単純な問題では、これらの推定量はかなり似ているべきです。事態が複雑になるときに初めて、物事は微妙になります。\n",
    "\n",
    "このシナリオは、モデルが非常に高次元のパラメータ $\\mu$ でパラメータ化されているものの、推論の対象となる量が $\\mu$ の低次元の要約であるというもので、セミパラメトリック統計学という名前の下で広く深く研究されています。\n",
    "\n",
    "セミパラメトリック統計学は、当然ながらパラメトリック統計学よりも難しく、またノンパラメトリック統計学よりもかなり挑戦的です。その理由は、特定の有限次元の要約の良い推定を保証したい場合、高次元パラメータの「良い」推定を一般的に得るだけでは不十分であることが判明するからです。実際、高次元パラメータの良い推定を得ることはしばしば不可能です（先ほど検討した例を参照）。\n",
    "\n",
    "その代わり、セミパラメトリックモデルを理解することは、何がうまく行われる必要があり、何を適当に済ませてよいかを理解する高度な技術となります。この説明は、単なるブログ投稿の範囲をはるかに超えてしまいますが、もしこのトピックについてもっと学びたいのであれば、それがググるべきキーワードです。\n",
    "\n",
    "## ロビンズとリトフは補助コインを投げ、戦争の犬を逃がす\n",
    "\n",
    "前の例の正しくて良いことすべてを破壊するために、私たちは一つだけ事をなす必要があります：悪意のある方法でランダム化することです。ロビンズとリトフ（実際には、有限の $J$ のケースを提案したワッサーマン）は、実験に $J$ 枚の偏ったコイン $r_j$ を加え、その性質は\n",
    "\n",
    "$$ \\Pr(r_j = 1 \\mid X=j) = \\xi_j, $$\n",
    "\n",
    "となります。ここで、 $\\xi_j$ は 既知 であり、$0 < \\delta \\leq \\xi_j < 1-\\delta$ を満たします（ $j=1,\\ldots, J$ 、ある $c>0$ に対して）。\n",
    "\n",
    "彼らは次にデータを見て回り、列 $r_i \\sim \\text{Bernouili}(\\xi_{x_i})$ を追加します。新しいデータは、3次元ベクトル $(y_i, x_i, r_i)$ となります。この問題において重要なのは、 $\\xi_j$ が既知であり、条件付き独立性 $y \\perp r \\mid x$ が成り立つことです。\n",
    "\n",
    "ロビンズ、リトフ、そしてワッサーマンは皆、同じ問いを投げかけます：条件付き分布 $(y_i, x_i) \\sim p(x,y \\mid r=1)$ からのサンプルのみを観測した場合でも、母集団平均を推定できるか？\n",
    "\n",
    "答えは、古典的な調査統計学には完全に優れた推定量が存在するが、ベイジアン推定量を見つけるのは少し難しい、ということになります。\n",
    "\n",
    "そこに至る前に、前のセクションの問題とは異なり、この問題は少なくとも少しは興味深いことを指摘しておく価値があります。これは、臨床試験における共変量依存のランダム化という非常に一般的な状況の戯画です。あるいは、もっと明確に言えば、単純な確率調査の戯画です。\n",
    "\n",
    "この問題の重要な特徴は、 $\\xi_j$ が既知で $p(x)$ も既知であるため、同時尤度が\n",
    "\n",
    "$$ p(y,x,r \\mid \\mu) = p(x)p(r\\mid x) p(y \\mid x, \\mu) = p(r , x) p(y \\mid x, \\mu), $$\n",
    "\n",
    "と分解できることです。したがって、 $r$ は $\\mu$ に対して補助的（ancillary）[^13]です。\n",
    "\n",
    "$\\mathbb{E}(y)$ の最も単純な古典的推定量は、ホルヴィッツ・トンプソン推定量です。\n",
    "\n",
    "$$ \\bar{y}_\\text{HT} = \\frac{1}{n} \\sum_{i=1}^n \\frac{y_i}{\\xi_{x_i}}. $$\n",
    "\n",
    "これが $\\sqrt{n}$ -consistentな推定量であることは簡単に示せます。さらに良いことに、この収束は推定量の収束が（主要な項において）特定の $\\mu_j$ の値に影響されないという意味で、 $\\mu$ に関して一様です。この一様性は、有限データでの良好な振る舞いに期待が持てるため、非常に有用です。\n",
    "\n",
    "さて、問題が解決できることがわかったので、ベイジアン的な方法で解決できるか見てみましょう。ロビンズとリトフは以下の結果を示しました。\n",
    "\n",
    "事前分布が $\\xi_j$ の値に依存しない限り、パラメータ $\\mu$ の一様にconsistentなベイジアン推定量は存在しない。\n",
    "\n",
    "ロビンズとリトフは、「コミットした主観的ベイジアン」は、尤度原理に従い、自身の事前分布が補助統計量 $\\xi$ に依存することを決して許さないだろうと主張します。なぜなら、尤度原理は、推論が補助的な情報から独立しているべきだと明確に述べているからです。\n",
    "\n",
    "もちろん、サンプリング確率に依存する事前分布を構築する方法はあります。ワッサーマンはこれを「頻度論追従（frequentist chasing）」と呼びます。\n",
    "\n",
    "それでは、これを調査してみましょう。何が間違っていたのか、どう修正するのか、そして、その修正がベイジアンとしての「純粋性」を損なうことになるのか、という点についても考察します。\n",
    "\n",
    "## 尤度原理とニュアンスの消滅\n",
    "\n",
    "では、尤度原理とは何で、なぜ我々ベイジアンにとって、これほど厄介な存在なのでしょうか？\n",
    "\n",
    "尤度原理とは、大まかに言えば、パラメータ推論[^14]に必要なすべての情報は尤度関数に含まれているべきだ、というものです。\n",
    "\n",
    "特に、尤度原理に従うならば、2つの尤度が互いにスカラー倍の関係にある場合、パラメータの推定値は同じになるべきです。\n",
    "\n",
    "なるほど。確かに。 一体なぜ人々は尤度原理を気にするのでしょうか？思うに、彼らはベイジアン手法が実際に機能するという事実に満足しておらず、代わりにベイジアン手法の優位性と純粋性を「証明」するために、非常に退屈な哲学もどきのことでもしたいのでしょう。まあ、彼らには彼らの自由です[^15]。あなたの趣味は私の趣味ではありません。\n",
    "\n",
    "この文脈では、 $r$ が $\\mu$ の推定において $y$ に対して補助的であるため、私たちは $\\mu$ を推定するために $r_i$ （および $\\xi_j$ ）を使用するのを避けるべきだ、ということになります。これは、ホルヴィッツ・トンプソン推定量が用いるものと真っ向から対立します。\n",
    "\n",
    "この原理に従うとどうなるか？悪い推定値が得られます。\n",
    "\n",
    "事後平均が最終的には真の値に収束することは、かなり容易に見て取れます。必要なのは、各カテゴリで十分な観測値を見ることだけです。ですから、十分なデータを得られれば、最終的には良い推定値が得られます。\n",
    "\n",
    "残念ながら、 $J$ が大きい場合、これには非常に、非常に長い[^16]時間がかかる可能性があります。\n",
    "\n",
    "もう少し深く掘り下げて、この振る舞いがそれ自体は間違っているわけではなく、ただベイジアン的である理由を見てみましょう。\n",
    "\n",
    "ベイジアン推論は、観測されたサンプルを条件とする事後分布を生成します。この事後分布は、観測されたサンプルと異なるパラメータ構成がどれほど両立可能かを表す、事前分布の更新です。\n",
    "\n",
    "問題は、私たちのサンプルが $x$ の値のごく一部しか見ていないことです。これは、私たちが本質的に推定しているのが\n",
    "\n",
    "$$ \\mathbb{E}x (\\mathbb{E}(y \\mid x) 1{x \\in A_{r}} \\mid r), $$\n",
    "\n",
    "であるということを意味します。ここで $A_r$ は観測された $x$ の値の集合で、 $r$ に依存します。このターゲットは、より多くのデータを得て、より多くの $x$ のレベルを見るにつれて変化し、最終的に私たちが計算しようとしているものへと合体していきます。\n",
    "\n",
    "しかし、そしてこれが重要なのですが、私たちは $j \\not \\in A_r$ である $\\mu_j$ については、それらが何らかの意味で非常に強く関連していると仮定できない限り、何も言えません。残念ながら、この例の要点は、私たちがそれを仮定することを許されていない[^17]ということなのです！\n",
    "\n",
    "この非常に柔軟なモデルでは、 $\\xi_j$ の系列が $\\mu_j$ と非常に高い相関[^18]を持つことが可能です。もし、例えば、 $\\text{expit}(\\mu_j) = \\xi_j$ が、ある小さな $\\delta>0$ に対して $[\\delta, 1-\\delta]$ 上に等間隔に[^19]配置されていたとすると、あなたは $y$ の最大値を観測する可能性が非常に高く、より小さな値のいずれかを観測する可能性はかなり低いという状況に陥ります。これは、あなたの標本平均を著しく上方に偏らせるでしょう。\n",
    "\n",
    "この構造は、ロビンズとリトフが、事後平均が真の平均に $(\\mathcal{O}((\\log \\log n)^2 \\log n))$ よりも速いレートで収束しない[^20]パラメータ値が常に存在することを証明するために用いたものと似ています。これでは、何らかの推論を行うために指数関数的に多くのサンプルが必要になります。\n",
    "\n",
    "この議論に対する合理的な批判は、ほとんどの問題ではサンプリング確率と条件付き平均の間に強い相関はないだろう、というものです。追跡論文で、リトフ らは、それが必ずしもそれほど珍しいことではないと主張しています。例えば、それらが両方とも独立したGP[^21]の実現である場合、観測された2つの系列間の経験的相関はゼロから大きく離れることがあります！もっと抽象的でない言い方をすれば、高齢者（しばしば電話に出る）には人気があるが、若者（通常は電話に出ない）には人気がないようなものを想像するのはかなり簡単です。したがって、この種の敵対的な相関は、実際には確かに起こり得るのです。\n",
    "\n",
    "この原理主義的なアプローチがもたらす困難を前に、ベイジアンは為すすべもないのでしょうか。それとも、問題の見方を変えることで活路は見出せるのでしょうか。\n",
    "\n",
    "## ベイズは救えるか？\n",
    "\n",
    "いいえ。 ベイズは救われる必要はありません。彼女は、やろうと決めたことを正確に行い、最高の人生を送っています。邪魔しないでください[^22]。\n",
    "\n",
    "では、なぜ物事を修正する必要がないのか見てみましょう。\n",
    "\n",
    "## 単純な事後分布とその事後処理\n",
    "\n",
    "もう一度、設定を思い出しましょう。私たちは三重項[^23]を観測しています。\n",
    "\n",
    "$$ z_i = (x_i,r_i,y_i) = (x_i, r_i, \\texttt{r[i]==1? y[i]: NA}). $$\n",
    "\n",
    "特に、このデータを処理していくつかの量を得ることができます。\n",
    "\n",
    "* $N$ ：総サンプルサイズ\n",
    "* $n= \\sum_{i=1}^N r_i$ ：観測された $y$ の数\n",
    "* $N_j = \\sum_{i=1}^N 1_{x_i = j}$ ：グループ $j$ がサンプリングされた総回数\n",
    "* $n_j = \\sum_{i=1}^N r_i1_{x_i = j}$ ：グループ $j$ からの観測が記録された回数\n",
    "\n",
    "問題の構造上、観測された $N_j$ と $n_j$ のほとんどの値は0か1になります。\n",
    "\n",
    "それでも、私たちは続けます。 次に、 $\\mu_j$ に対する事前分布が必要です。ここにはたくさんの選択肢があるでしょうが、私は最も単純なもの、つまり、ある固定された既知の値 $\\tau$ に対して、それらをi.i.d. $N(0, \\tau^2)$ とすることにします。そして、結果のモデルを適合させ、各 $\\mu_j$ の事後分布を得ることができます。データのスパース性のため、ほとんどの事後分布は事前分布と同じになることに注意してください。\n",
    "\n",
    "それから、私たちはもっとベイジアン的な問いを自問することができます：もし全ての $y_i$ を記録していたら、私たちのサンプルの平均はどうなっていただろうか？その量の最良の推定値は、\n",
    "\n",
    "$$ \\frac{1}{N}\\sum_{j=1}^J N_j \\mu_j $$\n",
    "\n",
    "です。\n",
    "\n",
    "それはそれで結構なことです。そして、もし私が十分に小さい $J$ か、あるいは十分に大きい $N$ を持っていて、全ての $\\mu_j$ に対して良い推定値を得られるなら、これは良い推定になるでしょう。さらに、有限のデータに対しては、これは $J^{-1}\\sum_{j=1}^J \\mu_j$ よりもずっと良い推定量になる可能性が高いです。なぜなら、共変量サンプリングにおける潜在的な不均衡を少なくとも部分的に補正するからです。\n",
    "\n",
    "ここでまた、これには「ベイジアン的」なことは何もない、と指摘しておく価値があります。私は単に、観測したサンプルから得た知識を取り入れ、関心のある量を計算するために事後処理を行っているだけです。\n",
    "\n",
    "しかし、もちろん、それは私が実際に興味を持っている量ではありません。私が興味を持っているのは、 $r$ の実現値にわたって平均されたその量です。 $n_j$ が $\\mu_j$ に与える影響を定量化できれば、これを計算できます。\n",
    "\n",
    "これはかなり簡単にできます。私たちの事前分布はi.i.d.[^24]なので、これは $J$ 個の独立した正規-正規モデルに分解されます。\n",
    "\n",
    "任意の $j$ について、 $y^{(j)}$ をカテゴリ $j$ に属する $y$ のサブセットとします。私たちは次の関係を持ちます[^25]。$$\\begin{align*} p(\\mu_j \\mid y) &\\propto \\exp\\left(-\\frac{1}{2}\\sum_{i=1}^{n_j}(y^{(j)}i - \\mu_j)^2 - \\frac{1}{2\\tau^2}\\mu_j^2\\right)\\\\ &\\propto \\exp\\left[-\\frac{1}{2}\\left(\\frac{1}{\\tau} + n_j\\right)\\mu_j^2 + \\mu_j\\sum{i=1}^{n_j}y_i^{(j)}\\right]. \\end{align*}$$ もし $\\mu_j \\mid y \\sim N(m,v^2)$ の密度を展開すると、 $$ p(\\mu_j \\mid y) \\propto \\exp\\left(-\\frac{1}{2v^2}\\mu_j^2 + \\frac{1}{v^2}m\\mu_j\\right). $$ となります。これら2つの式の項を一致させることで、 $$ v_j^\\text{post} = \\text{Var}(\\mu_j \\mid y, n_j) = \\frac{1}{n_j + \\tau^{-2}}, $$ となり、一方、事後平均は $$ m_j^\\text{post} = \\mathbb{E}(\\mu_j \\mid y, n_j) = \\frac{1}{n_j + \\tau^{-2}}\\sum_{i=1}^{n_j}y_i^{(j)}, $$ となります。ここで私は、真の[^26]ベイジアンとして、私のサンプルは固定され既知であるため、 $m_j$ と $v_j$ の表記においてサンプル $y$ への依存性を抑制しました。したがって、 $$ \\mu_j \\mid y \\sim N(m_j^{\\text{post}}, v_j^{\\text{post}}). $$ となります。\n",
    "\n",
    "そして、完全なサンプルの平均に対する次の推定量を得ます。 $$ \\mathbb{E}\\left(\\frac{1}{N}\\sum_{j=1}^JN_j\\mu_j \\mid y \\right)= \\frac{1}{N}\\sum_{j=1}^JN_jm_j^\\text{post}. $$ 事後分散も計算できます[^27]。 $$ \\text{Var}\\left(\\frac{1}{N}\\sum_{j=1}^JN_j\\mu_j \\mid y \\right)=\\sum_{j=1}^J\\frac{N_j^2}{N^2}v_j^\\text{post}. $$ ほとんどのグループには対応する観測値がないため、$A_r$ をサンプルで更新された $j$ の集合とすると、 $$ \\text{Var}\\left(\\frac{1}{N}\\sum_{j=1}^JN_j\\mu_j \\mid y \\right)=\\sum_{j\\in A_r}\\frac{N_j^2}{N^2}v_j^\\text{post} + \\tau^2\\sum_{j \\not \\in A_r}\\frac{N_j^2}{N^2}, $$ となり、ここで $\\tau^2$ にかかる項は1未満です。\n",
    "\n",
    "これはこれで結構ですが、私たちが推定しようとしていたものではありません。私たちが実際に興味を持っているのは、 $N\\rightarrow \\infty$ としたときに得られる母集団平均を推定することです。\n",
    "\n",
    "では、普遍的に合意された神聖なベイズの厳格な教義に違反することなく、これを実行できるか見てみましょう。\n",
    "\n",
    "## 補助的なコインの効果のモデリング\n",
    "\n",
    "しかし、重要なのはここからです。私たちは事後分布 $p(\\mu_j \\mid y)$ を計算し、今やこれをデータの生成モデル[^28]として使用することができます。また、完全なデータセットの構成（ $N_j$ ）と、$n_j$ の新しいサンプルがどのように私たちの世界に現れるかについての完全な知識も持っています。\n",
    "\n",
    "これらのものを組み合わせることができます！そしてそれは、私たちのベイジアンとしての誓いをいかなる形でも破るものではありません！私たちは単に、完全に合法的に得た事後分布を使って物事を計算しているだけです。私たちは依然として真のコミットした[^29]主観的ベイジアンです。\n",
    "\n",
    "そこで、私たちは自分たちに簡単な問いを投げかけます。与えられた $N_j$ に対して、$n_j \\sim \\text{Binom}(N_j, \\xi_j)$ 個のi.i.d.サンプル[^30] $$ \\tilde{y}^{(j)}_i \\sim N(m_j^\\text{post}, v_j^\\text{post} + 1). $$ があったと想像してください。このときの事後平均 $\\mathbb{E}(\\mu_j \\mid \\tilde{y}^{(j)}, N_j)$ は何でしょうか？実際、これは仮説上のサンプルから抽出されたランダムなデータなので、その分布について問いを立てることができます（そしてそうすべきです[^31]）！率直に言うと、事後平均の分散を計算するのは面倒なので、私は事後平均の平均だけを見ることにします。\n",
    "\n",
    "まず第一に、$n_j = n$ のときの $\\mu_j$ の（平均的な）事後分布を見る必要があります。先ほど行った正確な計算から、サンプルサイズが $n$ のときの事後平均の平均は $$ m_j(n) = \\left(1-\\frac{1}{\\tau^2n + 1}\\right) m_j^\\text{post}. $$ となります。そして、分散には焦点を当てないと言いましたが、 $$ v_j(n) = \\frac{1}{n + \\tau^{-2}} + \\left(1 - \\frac{1}{\\tau^2n + 1}\\right)(1 + v^\\text{post}_j), $$ と書き下すのは十分に簡単です。ここで第2項は、補完（imputation）による分散を考慮に入れています。\n",
    "\n",
    "これを用いて、任意の数 $\\tilde N$ 、合計が $\\tilde N$ となる任意の $\\tilde N_j$ の集合、そして任意の $\\tilde n_j \\sim \\text{Binom}(\\tilde N_j, \\xi_j)$ の集合に対して、標本平均を $$ \\begin{align*} \\frac{1}{\\tilde N}\\sum_{j=1}^J \\tilde N_j m_j(n_j) &= \\frac{1}{\\tilde N}\\sum_{j=1}^J \\frac{\\tilde N_j}{\\tilde n_j} \\tilde n_j m_j(n_j) \\ &= \\frac{1}{\\tilde N}\\sum_{j=1}^J \\frac{1}{\\xi_j} \\tilde n_j m_j^\\text{post} + o(1), \\end{align*} $$ と推定できます。ここで最後の行では、経験的比率が $\\xi_j$ に収束し、事後平均が $m_j^\\text{post}$ に収束するという事実を用いました。リトル・オー[^32]の誤差項は、 $\\tilde N$ （したがって $\\tilde N_j$ と $\\tilde n_j$ も）が無限大になるときに現れます。\n",
    "\n",
    "これを実用的な推定値に変えるために、$n_j$ と $N$ の値を代入して、母集団平均に対するベイジアン近似を得ることができます。 $$ \\begin{align*} \\hat \\mu &= \\frac{1}{N}\\sum_{j=1}^J \\frac{n_j}{\\xi_j}m_j^{\\text{post}} \\ &=\\frac{1}{N} \\sum_{j \\in A_r} \\frac{n_j}{\\xi_j}m_j^\\text{post} \\ &=\\frac{1}{N}\\sum_{j=1}^J\\sum_{i=1}^{n_j} \\frac{1}{\\xi_j}\\left(1 - \\frac{\\tau^{-2}}{n_j}\\right)y_i^{(j)}, \\end{align*} $$ これは括弧内の小さな補正項を除けば、まさしくホルヴィッツ・トンプソン推定量に他なりません！\n",
    "\n",
    "## これはベイジアンか？\n",
    "\n",
    "私は再び強調しますが、この導出には本質的に非ベイジアン的なことは何もありません。おそらく、それが問いかけている問いを除いては。私が行ったのは、事後分布を計算し、それを真剣に受け止め、関心のある量を計算するために使用した、ということです。\n",
    "\n",
    "唯一の奇妙な点は、関心のある量（母集団平均）が、観測されたサンプルと少し厄介なつながりを持っていることです。したがって、私は母集団平均とより直接的なつながりを持つ何か、すなわち、ランダム化 $r_i$ の異なる実現の下での完全に観測されたサンプルの標本平均を推定しました。\n",
    "\n",
    "ランダム化の異なる実現の下での標本平均を推定するために、私はこれらの架空のサンプルを補完するために事後予測分布を使用する必要がありました。そして、補完されたサンプルにわたって平均を取り、サンプルサイズを無限大に送ることで、推定量[^33]を得ました。\n",
    "\n",
    "言い換えれば、私はベイズを使って新しいデータに対する事後推定値 $$ p(\\tilde y, \\tilde r, \\tilde x) = \\int_{\\mathbb{R}^J}p(\\tilde y \\mid \\tilde x, \\mu),d\\mu p(\\tilde r \\mid \\tilde x) p(\\tilde x) $$ を得て、それからこの確率モデルを使って $\\mathbb{E}(\\tilde y)$ を推定しました。これを行うのにベイジアン手法を使う理由は全くありませんでした。非ベイジアン的な問いは、ベイジアン的な答えを招きません。\n",
    "\n",
    "さて、実生活で私がこれだけの労力を払うか？おそらくしないでしょう。そして、私がこれまでに出会った応用例では、そうする必要はありませんでした。私はMRP[^34]をたくさんやってきましたが、これは構造的にこの問題と非常に似ていますが、 $\\mu_j$ 間の依存構造を合理的にモデル化できる点が異なります。アレックス・ガオ、ローレン・ケネディ、アンドリュー・ゲルマンと書いたこの論文は、あなたができるモデリングの一例です。\n",
    "\n",
    "ベイジアンの枠組み内で問題を解決できることを示しましたが、これはワッサーマンが批判するような「頻度論追従」なのでしょうか？最終セクションでは、この問いに答えていきます。\n",
    "\n",
    "### 本当か？私は追従者なのか？\n",
    "\n",
    "ワッサーマンは「頻度論追従」のベイジアンを嘲笑し、もし彼らがそんなに頻度論的な保証を望むなら、なぜ簡単な方法でやらないのか、と指摘します。\n",
    "\n",
    "さて。ラズ。友よ。 私の自尊心の多くは伝統的に追従者から得られてきたものだから、その中傷に加担することは絶対に拒否させてもらうよ。\n",
    "\n",
    "しかしそれ以上に、明確にしておきましょう。ベイズとは、データを確率的に記述する方法です。それ自体だけでは有用であるとは言えません。それが有用であるためには、その事後分布を使って何かをする必要があります。\n",
    "\n",
    "では、真のコミットした主観的ベイジアンがこれについてどうするか、本当に話してみましょう。まず第一に、本当に。そんなものは存在しません[^35]。しかしそれをさておき、私がたどり着ける最も近い実用的な定義は、真のコミットした主観的ベイジアンとは、パラメータがデータを記述するために用いられる丁寧なフィクションであることを理解している人だ、というものです。それらは本質的に、いかなる母集団の量とも結びついていません（真のコミットした主観的ベイジアンにとって、そのようなものは存在しないのです）。\n",
    "\n",
    "ベイジアンモデルのパラメータを関心のある母集団の量と結びつける唯一の方法は、何らかのベイジアンの枠組み外[^36]の情報を使用することです。\n",
    "\n",
    "例えば、最初の例（補助的なコインがないもの）では、私はサンプルの仮定を使って秘密裏にその結びつきを作りました。私たちは皆、そのような仮定が危険を伴うものであり、人々が眠っている恋人の耳にDAGをささやくのに多くの時間を費やす理由であることを知っています。\n",
    "\n",
    "補助的なコインの例では、与えられたサンプリングメカニズムに関する情報を、私たちの事後分布を関心のある母集団の量と結びつけるための追加情報として使用しました。これらのいずれも、ベイジアン分析の純粋性[^37]を変えるものではありません。あるいは、非ベイジアン的な解決策を好ましいものにするわけでもありません。（もっとも、このケースでは、非ベイジアン的な解決策を思いつく方がくそほど簡単ですが。）\n",
    "\n",
    "もちろん、ワッサーマン（そしておそらくロビンズとリトフも）はこれらすべてを知っています。しかし、それをすべて書き留めるのは楽しいものです。\n",
    "\n",
    "さらに、ここでの3つの教訓はかなり応用可能だと思います。\n",
    "\n",
    "1. 事後分布を計算する手間をかけるなら、それを真剣に受け止めなさい。それを使って何かをしなさい！それを確率モデルの一部として組み込むことさえできます。\n",
    "2. ベイズを自分のために役立てるなら、パラメータではなく、観測可能な量（例：完全なサンプルの平均）の観点から考えなさい。\n",
    "3. 純粋性を訴えることは、時間の無駄です。\n",
    "\n",
    "## 引用情報\n",
    "\n",
    "BibTeX citation: @online{simpson2022, author = {Simpson, Dan}, title = {On That Example of {Robins} and {Ritov;} or {A} Sleeping Dog in Harbor Is Safe, but That’s Not What Sleeping Dogs Are For}, date = {2022-11-15}, url = {https://dansblog.netlify.app/posts/2022-11-12-robins-ritov/robins-ritov.html}, langid = {en} }\n",
    "\n",
    "For attribution, please cite this work as: Simpson, Dan. 2022. “On That Example of Robins and Ritov; or A Sleeping Dog in Harbor Is Safe, but That’s Not What Sleeping Dogs Are For.” November 15, 2022. https://dansblog.netlify.app/posts/2022-11-12-robins-ritov/robins-ritov.html.\n",
    "\n",
    "## 脚注\n",
    "\n",
    "[^1]: 素晴らしいコメントをくれたSameer Deshpandeに心から感謝します！ \n",
    "\n",
    "[^2]: 私がこれに初めて出会ったのは、ラリー・ワッサーマンの今はなき、しかし非常に優れたブログの一連の投稿でした。 \n",
    "\n",
    "[^3]: この3人は、私が普段行わない形式の素晴らしい統計学を行っていることは言うまでもありません。しかし、だからといって彼らの貢献を理解することの重要性が減るわけではありません。私はラズビアンではありませんが、理論を知ることは重要だと思います。 \n",
    "\n",
    "[^4]: 少し言い回しを変えたかもしれません。 \n",
    "\n",
    "[^5]: 純粋さが必要なのは良質なオリーブオイルだけで、それ以外にはありません。 \n",
    "\n",
    "[^6]: コミットした主観的ベイジアンは、ダッチブックよりもダッチベイビーを好みます。 \n",
    "\n",
    "[^7]: 真のコミットした主観的ベイジアンは、キルトの下に何も着用しません。 \n",
    "\n",
    "[^8]: すなわち、すべての $\\epsilon>0$ に対して $\\Pr(|\\hat \\mu_n - \\mu| > \\sqrt{n}\\epsilon) \\rightarrow 0$ となる推定量です。これは大まかに言って、高い確率で $\\mu \\in [ \\hat \\mu_n - C\\sqrt{n}, \\hat \\mu_n + C\\sqrt{n}]$ となるような $C$ を見つけられることを意味します。 \n",
    "\n",
    "[^9]: 漸近論によれば、データを $J$ の倍数で数えるべきであり、小数点以下1桁の精度を得るためでさえ $n > 100J$ が必要になります。 \n",
    "\n",
    "[^10]: $\\mu_j = \\mathbb{E}(y \\mid x=j)$ であることを思い出してください。 \n",
    "\n",
    "[^11]: HarmelingとToussaintの定理2。 \n",
    "\n",
    "[^13]: もし出会ったことがなければ、補助的（ancillary）どんなモデル $p(y\\mid x, \\theta)$ に対しても補助的であることを見る一つの方法は、同時密度の対数を考えることです。 $$ \\log(p(x,y,r \\mid \\theta)) = \\log p(y\\mid x, \\theta) + \\log p(r \\mid x) + \\log p(x) $$ となり、最後の2項は $\\theta$ に関して定数です。 \n",
    "\n",
    "[^14]: ここでは具体的にする必要があります。明らかに、統計的予測をしようとしていたり、意思決定をしようとしていたりする場合には、これは偽になります。それらのことは必然的に追加のものに依存します！ \n",
    "\n",
    "[^15]: これは嘘です。実際にベイズを役立たせ、新しくエキサイティングな方法でベイジアン手法なしでは難しいことを行う代わりに、この手の話に固執するのは時間の無駄です。それ以上に悪いのは、自分の選んだ手法が分別のある principled な人間が使う唯一可能なものだと見せかけ始めると、ちょっと頭のおかしい奴のように見え始めることです。それはまた、人々がこれらの非常に柔軟で有用な手法を試すのを思いとどまらせます。だから、ええ。私は少しは気にかけているかもしれません。 \n",
    "\n",
    "[^16]: $x_i =j$ となる1回の抽選を見るための期待サンプル数は $J$ です。$x_i = j$ となる抽選で、対応する $y_i$ を実際に観測するために必要な期待回数は $\\xi_j^{-1}$ です。これは、各カテゴリから実質的に1つのサンプルを得るだけでも、ましてやある種の合理的な推定値を得るために必要な20〜100を得るには、たくさんの抽選が必要になる可能性があることを示唆しています。 \n",
    "\n",
    "[^17]: ロビンズとリトフは、もし $\\mathbb{E}(Y \\mid x = j)$ に対する真のパラメトリックモデルが存在する場合（あるいはその関数が何らかの技術的な意味で「非常に滑らか」である場合、例えば滑らかなガウス過程の実現である場合）、この情報を取り入れたベイジアン推定量は完璧にうまく機能すると常に公言しています。 \n",
    "\n",
    "[^18]: RRの例では二値データを使用しているので、その場合は $\\mathbb{E}(y \\mid x=j)$ と $\\xi_j$ の間の相関になりますが、$\\xi_j$ が $\\text{expit}(\\mu_j)$ のようなものと相関している場合でも、まったく同じ議論が成り立ちます。私がガウス版を選んだのは、ある時点で事後分布を導出しなければならなくなるかもしれないと思ったからで、私は単純さを何よりも重視しています。 \n",
    "\n",
    "[^19]: expitはlogit変換の逆関数です。 \n",
    "\n",
    "[^20]: 状況は私がここでスケッチしているものと若干異なりますが、実質的な違いはないので、詳細は論文を確認してください。 \n",
    "\n",
    "[^21]: もちろん、もしこれが真実なら、$\\mu_j$ にGP事前分布を使用することができ、おそらくそれでもまともな推定量が得られるでしょう。 \n",
    "\n",
    "[^22]: もし干渉したいなら、$\\xi_j$ の情報を取り入れる事前分布を構築する方法はたくさんあります。リトフらの論文には、この例から生まれた様々なものへの良い参考文献があります。これらは、$\\mu$ の事後平均が $\\mathbb{E}(y)$ を推定することを確実にする以上に有用でしょうか？そうでもありません。それらは、まさに一つの問題を解決するために設計された事前分布です。 \n",
    "\n",
    "[^23]: C/C++の三項演算子を使っています。Rではこれは ifelse(r[i] == 1, y[i], NA) と解釈されます。 \n",
    "\n",
    "[^24]: 交換可能ではありません—共有パラメータはありません！ \n",
    "\n",
    "[^25]: $y \\mid x = j \\sim N(\\mu_j, 1)$ であることを思い出してください。もっと柔軟な分散が必要なら、もちろん持つことはできますが、何にも実質的な違いはありません。 \n",
    "\n",
    "[^26]: 私はただ、自分の脳が見えるかどうか、目を回しているだけだと約束します。 \n",
    "\n",
    "[^27]: すべてが独立していることを思い出してください！ \n",
    "\n",
    "[^28]: これは事後予測分布です！ \n",
    "\n",
    "[^29]: 真のコミットした主観的ベイジアンは、DPがディリクレ過程（Dirichlet Process）の略であることを知っています。どんな文脈であっても。 \n",
    "\n",
    "[^30]: これは事後予測分布なので、分散は $v_j^\\text{post} + 1$ です。 \n",
    "\n",
    "[^31]: これは頻度論的な問いのように思えますか？そうかもしれません。しかし実際には、これは私たちが常に事後分布について尋ねることができる問いです。そうすべきでしょうか？まあ、もし母集団の量を推定しようとしているなら、ある意味でそうしなければなりません。なぜなら、ベイジアンの枠組み（真のコミットした主観的であろうとなかろうと）の中には、母集団パラメータという概念は実質的に存在しないからです。 \n",
    "\n",
    "[^32]: これが意味するのは、誤差（確率変数）が $n \\rightarrow \\infty$ となるときに0に近づくということです。もっと注意深い人なら、おそらくそれがどれくらいの速さで起こるかを計算できるでしょう。 \n",
    "\n",
    "[^33]: 私は平均しか計算しなかったので、私が損失関数を最小化していると自由に想像してください。 \n",
    "\n",
    "[^34]: 多階層回帰と事後層別化、調査モデリングの手法。 \n",
    "\n",
    "[^35]: ノー・トゥルー・スコッツマンなど。 \n",
    "\n",
    "[^36]: あるいは、私たちが検討中のすべてのモデルの空間上でベイジアン疑似モデルを構築しているような場合にはメタ・ベイジアン。そのモデルがたまたま全てのモデルに等しい確率を与えるのは、ハロルド・ファッキン・ジェフリーズがあなたを興奮させ、あなたはその出来事を大人のように処理するか、それともそれに基づいて全人格を構築するかの選択を迫られ、後者を選んだからです。 \n",
    "\n",
    "[^37]: 私がこの議論全体を嫌っていることが伝わりますか？"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,jl:hydrogen"
  },
  "kernelspec": {
   "display_name": "Julia",
   "language": "julia",
   "name": "julia"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
