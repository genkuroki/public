{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0bf5239-bf5a-45c0-be98-83b709262f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "using StaticArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35df30e8-7088-4648-acc1-76690108ca03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360-element CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 0.0\n",
       " 0.017453292\n",
       " 0.034906585\n",
       " 0.05235988\n",
       " 0.06981317\n",
       " 0.08726646\n",
       " 0.10471976\n",
       " 0.12217305\n",
       " 0.13962634\n",
       " 0.15707964\n",
       " 0.17453292\n",
       " 0.19198622\n",
       " 0.20943952\n",
       " ⋮\n",
       " 6.0737457\n",
       " 6.091199\n",
       " 6.1086526\n",
       " 6.126106\n",
       " 6.143559\n",
       " 6.161012\n",
       " 6.1784654\n",
       " 6.195919\n",
       " 6.213372\n",
       " 6.2308254\n",
       " 6.2482786\n",
       " 6.265732"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "θ = range(0, 2π; length=361)[1:end-1]\n",
    "θ_cu = cu(collect(θ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd31a9d6-bdc7-4050-94dd-a4c97417ef9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_smf32(t) = @SMatrix(Float32[\n",
    "    cos(t) -sin(t) 0\n",
    "    sin(t)  cos(t) 0\n",
    "    0      0       1\n",
    "])\n",
    "\n",
    "f(t) = r_smf32(t) * @SVector Float32[1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a51aa6-1aee-4d7b-be69-ba750a329aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360-element CuArray{SVector{3, Float32}, 1, CUDA.Mem.DeviceBuffer}:\n",
       " [1.0, 0.0, 0.0]\n",
       " [0.9998477, 0.017452406, 0.0]\n",
       " [0.99939084, 0.034899496, 0.0]\n",
       " [0.9986295, 0.05233596, 0.0]\n",
       " [0.9975641, 0.06975647, 0.0]\n",
       " [0.9961947, 0.08715574, 0.0]\n",
       " [0.9945219, 0.104528464, 0.0]\n",
       " [0.99254614, 0.12186935, 0.0]\n",
       " [0.99026805, 0.1391731, 0.0]\n",
       " [0.98768836, 0.15643448, 0.0]\n",
       " [0.9848077, 0.17364818, 0.0]\n",
       " [0.98162717, 0.190809, 0.0]\n",
       " [0.9781476, 0.2079117, 0.0]\n",
       " ⋮\n",
       " [0.97814757, -0.20791176, 0.0]\n",
       " [0.98162717, -0.19080916, 0.0]\n",
       " [0.9848078, -0.17364797, 0.0]\n",
       " [0.98768836, -0.15643436, 0.0]\n",
       " [0.99026805, -0.13917309, 0.0]\n",
       " [0.99254614, -0.12186943, 0.0]\n",
       " [0.99452186, -0.10452865, 0.0]\n",
       " [0.9961947, -0.08715556, 0.0]\n",
       " [0.9975641, -0.06975638, 0.0]\n",
       " [0.9986295, -0.052335963, 0.0]\n",
       " [0.99939084, -0.0348996, 0.0]\n",
       " [0.9998477, -0.017452609, 0.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.(θ_cu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ed56b7-6fb5-4178-b77c-4828d2e264f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA, NNlib, NNlibCUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00874ff5-f260-4ab7-96c0-85f8197a0ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mh\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1m_\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mc\u001b[22m \u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mh\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1m_\u001b[22mmul \u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mh\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1m_\u001b[22mmul! \u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mh\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1m_\u001b[22madjoint \u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mh\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1m_\u001b[22mtranspose\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "batched_vec(A::Array{T,3}, B::Matrix)\n",
       "batched_vec(A::Array{T,3}, b::Vector)\n",
       "\\end{verbatim}\n",
       "Batched matrix-vector multiplication: the result has \\texttt{C[:,:,k] == A[:,:,k] * B[:,k]} for all \\texttt{k}, or else \\texttt{C[:,:,k] == A[:,:,k] * b} for \\texttt{b::Vector}.\n",
       "\n",
       "With the same argument types, \\texttt{batched\\_mul(A, B)} would regard \\texttt{B} as a fixed matrix, not a batch of vectors. Both reshape and then call \\texttt{batched\\_mul(::Array\\{T,3\\}, ::Array\\{T,3\\})}.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> A, B, b = randn(16,8,32), randn(8,32), randn(8);\n",
       "\n",
       "julia> batched_vec(A,B) |> size\n",
       "(16, 32)\n",
       "\n",
       "julia> batched_vec(A,b) |> size\n",
       "(16, 32)\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "batched_vec(A::Array{T,3}, B::Matrix)\n",
       "batched_vec(A::Array{T,3}, b::Vector)\n",
       "```\n",
       "\n",
       "Batched matrix-vector multiplication: the result has `C[:,:,k] == A[:,:,k] * B[:,k]` for all `k`, or else `C[:,:,k] == A[:,:,k] * b` for `b::Vector`.\n",
       "\n",
       "With the same argument types, `batched_mul(A, B)` would regard `B` as a fixed matrix, not a batch of vectors. Both reshape and then call `batched_mul(::Array{T,3}, ::Array{T,3})`.\n",
       "\n",
       "```jldoctest\n",
       "julia> A, B, b = randn(16,8,32), randn(8,32), randn(8);\n",
       "\n",
       "julia> batched_vec(A,B) |> size\n",
       "(16, 32)\n",
       "\n",
       "julia> batched_vec(A,b) |> size\n",
       "(16, 32)\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  batched_vec(A::Array{T,3}, B::Matrix)\u001b[39m\n",
       "\u001b[36m  batched_vec(A::Array{T,3}, b::Vector)\u001b[39m\n",
       "\n",
       "  Batched matrix-vector multiplication: the result has \u001b[36mC[:,:,k] == A[:,:,k] *\n",
       "  B[:,k]\u001b[39m for all \u001b[36mk\u001b[39m, or else \u001b[36mC[:,:,k] == A[:,:,k] * b\u001b[39m for \u001b[36mb::Vector\u001b[39m.\n",
       "\n",
       "  With the same argument types, \u001b[36mbatched_mul(A, B)\u001b[39m would regard \u001b[36mB\u001b[39m as a fixed\n",
       "  matrix, not a batch of vectors. Both reshape and then call\n",
       "  \u001b[36mbatched_mul(::Array{T,3}, ::Array{T,3})\u001b[39m.\n",
       "\n",
       "\u001b[36m  julia> A, B, b = randn(16,8,32), randn(8,32), randn(8);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> batched_vec(A,B) |> size\u001b[39m\n",
       "\u001b[36m  (16, 32)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> batched_vec(A,b) |> size\u001b[39m\n",
       "\u001b[36m  (16, 32)\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?batched_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51552a3c-10be-427f-bf42-709774e1e155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3×360 CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}:\n",
       "[:, :, 1] =\n",
       " 1.0  -0.0  0.0\n",
       " 0.0   1.0  0.0\n",
       " 0.0   0.0  1.0\n",
       "\n",
       "[:, :, 2] =\n",
       " 0.999848   -0.0174524  0.0\n",
       " 0.0174524   0.999848   0.0\n",
       " 0.0         0.0        1.0\n",
       "\n",
       "[:, :, 3] =\n",
       " 0.999391   -0.0348995  0.0\n",
       " 0.0348995   0.999391   0.0\n",
       " 0.0         0.0        1.0\n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 358] =\n",
       "  0.99863   0.052336  0.0\n",
       " -0.052336  0.99863   0.0\n",
       "  0.0       0.0       1.0\n",
       "\n",
       "[:, :, 359] =\n",
       "  0.999391   0.0348995  0.0\n",
       " -0.0348995  0.999391   0.0\n",
       "  0.0        0.0        1.0\n",
       "\n",
       "[:, :, 360] =\n",
       "  0.999848   0.0174524  0.0\n",
       " -0.0174524  0.999848   0.0\n",
       "  0.0        0.0        1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R(t) = [\n",
    "    cos(t) -sin(t) 0\n",
    "    sin(t)  cos(t) 0\n",
    "    0      0       1\n",
    "]\n",
    "\n",
    "θ = range(0, 2π; length=361)[1:end-1]\n",
    "A = mapslices(t -> R(t[1, 1]), reshape(θ, 1, 1, :); dims=(1, 2))\n",
    "A_cu = cu(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5276a85-9942-420d-bd80-64f5175bb83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×360 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 1.0  0.999848   0.999391   0.99863   …   0.99863    0.999391    0.999848\n",
       " 0.0  0.0174524  0.0348995  0.052336     -0.052336  -0.0348995  -0.0174524\n",
       " 0.0  0.0        0.0        0.0           0.0        0.0         0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_vec(A_cu, cu([1.0, 0.0, 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6652c278-0b51-47e6-9393-d922becde857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×360 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 1.0  0.999848   0.999391   0.99863   …   0.99863    0.999391    0.999848\n",
       " 0.0  0.0174524  0.0348995  0.052336     -0.052336  -0.0348995  -0.0174524\n",
       " 0.0  0.0        0.0        0.0           0.0        0.0         0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CUDA, NNlib, NNlibCUDA\n",
    "\n",
    "R(t) = [\n",
    "    cos(t) -sin(t) 0\n",
    "    sin(t)  cos(t) 0\n",
    "    0      0       1\n",
    "]\n",
    "\n",
    "θ = range(0, 2π; length=361)[1:end-1]\n",
    "A = mapslices(t -> R(t[1, 1]), reshape(θ, 1, 1, :); dims=(1, 2))\n",
    "batched_vec(cu(A), cu([1.0, 0.0, 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01284811-a62c-478a-887b-c7e47b83aca5",
   "metadata": {},
   "source": [
    "See also https://discourse.julialang.org/t/how-to-broadcast-or-batch-multiply-a-batch-of-matrices-with-another-matrix-on-the-gpu/67259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb1017e-6939-4432-9ff0-b5f762dd52f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:hydrogen"
  },
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
